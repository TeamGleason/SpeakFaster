"""Module for processing videos."""

import os
import shutil
import subprocess
import tempfile

from PIL import Image
import ffmpeg
import numpy as np

import file_naming


def stitch_images_into_mp4(image_paths,
                           start_time_epoch_s,
                           timezone,
                           out_mp4_path):
  """Stitch a series of images of the same size into a video.

  The video will have no audio track.

  image_paths: The paths to the images.
  start_time_epoch_s: Seconds since epoch of the starting time. Frames
    that are before it are discarded. The time gap between this starting
    time and the time of the first included frame are filled with a
    blank (black) frame.
  timezone: Name of the timezone for the timestamps in the image file names.
  output_mp4_path: Path to the output mp4 video file.
  """
  if not image_paths:
    raise ValueError("Empty image paths")

  # Find the first image path to include.
  image_paths = sorted(image_paths)
  for start_index, image_path in enumerate(image_paths):
    video_start_epochs_s = file_naming.parse_epoch_seconds_from_filename(
        image_path, timezone)
    if video_start_epochs_s >= start_time_epoch_s:
      initial_frame_duration_s = video_start_epochs_s - start_time_epoch_s
      break
  print("The screenshot video file will start from frame %d (0-based); "
        "Discarding %d frames." % (start_index, start_index))
  image_paths == image_paths[start_index:]

  tmp_dir = tempfile.mkdtemp()
  pts = [0]

  # Get the dimensions of the first image.
  image_width, image_height = Image.open(image_paths[0]).size
  # Create the image file for the first frame.
  if initial_frame_duration_s > 0:
    print("Creating an initial blank frame with duration %f s" %
          initial_frame_duration_s)
    initial_frame_image_path = os.path.join(tmp_dir, "first_frame.jpg")
    Image.new("RGB", (image_width, image_height)).save(initial_frame_image_path)

  timestamp0, _ = file_naming.parse_timestamp_from_filename(image_paths[0])
  for image_path in image_paths[1:]:
    timestamp, _ = file_naming.parse_timestamp_from_filename(image_path)
    if timestamp < timestamp0:
      raise ValueError(
          "Timestamp of image file is out of order: %s" % image_path)
    dt = timestamp - timestamp0
    pts.append(dt.seconds + dt.microseconds / 1e6)
  frame_durations_s = np.diff(pts)
  n_images = len(image_paths)

  input_file_path = os.path.join(tmp_dir, "input.txt")
  with open(input_file_path, "w") as f:
    if initial_frame_duration_s > 0:
      f.write("file %s\n" % normalize_path(initial_frame_image_path))
      f.write("duration %.6f\n" % initial_frame_duration_s)
    for i in range(n_images):
      f.write("file %s\n" % normalize_path(image_paths[i]))
      if i < n_images - 1:
        f.write("duration %.6f\n" % frame_durations_s[i])

  subprocess.check_call([
      "ffmpeg", "-f", "concat", "-safe", "0",
      "-i", input_file_path, out_mp4_path])
  shutil.rmtree(tmp_dir)


def normalize_path(file_path):
  """Normalizes path for ffmpeg, which requires forward slash.

  This is the case even on Windows.
  """
  return "/".join(file_path.split(os.path.sep))


def make_dummy_video_file(duration_s,
                          frame_image_path,
                          output_video_path,
                          fps=1.0):
  """Generates a dummy video file.

  The video is generated by repeating a single frame of image at a
  frame rate of 1 fps for the specified duration.
  This is useful when there is no video data collected in the session.

  Args:
    duration_s: Duration of the video in seconds.
  """
  stream = ffmpeg.input(
      frame_image_path, pattern_type="glob", framerate=fps,
      stream_loop=np.ceil(duration_s) / fps)
  stream.output(normalize_path(output_video_path)).run()
